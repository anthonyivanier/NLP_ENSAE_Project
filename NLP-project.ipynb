{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import des données et traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Chargement des données des prénoms\n",
    "df_prenoms = pd.read_csv('/Users/anthonyivanier/Desktop/Ensae/3A/NLP/firstname_with_sex.csv', sep=';')\n",
    "\n",
    "# Chargement des transcriptions\n",
    "df_transcriptions = pd.read_csv('/Users/anthonyivanier/Desktop/Ensae/3A/NLP/transcriptions_with_sex.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firstname</th>\n",
       "      <th>male</th>\n",
       "      <th>female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>marie</td>\n",
       "      <td>10145</td>\n",
       "      <td>2390322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jean</td>\n",
       "      <td>1869615</td>\n",
       "      <td>6476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pierre</td>\n",
       "      <td>1475841</td>\n",
       "      <td>5047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jeanne</td>\n",
       "      <td>1765</td>\n",
       "      <td>1097397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>françois</td>\n",
       "      <td>1089009</td>\n",
       "      <td>5951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>joseph</td>\n",
       "      <td>897742</td>\n",
       "      <td>4246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>anne</td>\n",
       "      <td>1479</td>\n",
       "      <td>816241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>marguerite</td>\n",
       "      <td>1441</td>\n",
       "      <td>813859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>catherine</td>\n",
       "      <td>1223</td>\n",
       "      <td>792448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>louis</td>\n",
       "      <td>750498</td>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>françoise</td>\n",
       "      <td>1153</td>\n",
       "      <td>600167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jacques</td>\n",
       "      <td>585567</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>antoine</td>\n",
       "      <td>536089</td>\n",
       "      <td>2067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>nicolas</td>\n",
       "      <td>408007</td>\n",
       "      <td>1463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>louise</td>\n",
       "      <td>681</td>\n",
       "      <td>360914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>claude</td>\n",
       "      <td>324134</td>\n",
       "      <td>4830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>charles</td>\n",
       "      <td>276133</td>\n",
       "      <td>972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>elisabeth</td>\n",
       "      <td>353</td>\n",
       "      <td>224969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>madeleine</td>\n",
       "      <td>424</td>\n",
       "      <td>217939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>michel</td>\n",
       "      <td>214487</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>etienne</td>\n",
       "      <td>211297</td>\n",
       "      <td>898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>guillaume</td>\n",
       "      <td>197634</td>\n",
       "      <td>792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>claudine</td>\n",
       "      <td>280</td>\n",
       "      <td>163711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>andré</td>\n",
       "      <td>160970</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>yves</td>\n",
       "      <td>156916</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>henri</td>\n",
       "      <td>151366</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>antoinette</td>\n",
       "      <td>326</td>\n",
       "      <td>150155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firstname     male   female\n",
       "0        marie    10145  2390322\n",
       "1         jean  1869615     6476\n",
       "2       pierre  1475841     5047\n",
       "3       jeanne     1765  1097397\n",
       "4     françois  1089009     5951\n",
       "5       joseph   897742     4246\n",
       "6         anne     1479   816241\n",
       "7   marguerite     1441   813859\n",
       "8    catherine     1223   792448\n",
       "9        louis   750498     2720\n",
       "10   françoise     1153   600167\n",
       "11     jacques   585567     2010\n",
       "12     antoine   536089     2067\n",
       "13     nicolas   408007     1463\n",
       "14      louise      681   360914\n",
       "15      claude   324134     4830\n",
       "16     charles   276133      972\n",
       "17   elisabeth      353   224969\n",
       "18   madeleine      424   217939\n",
       "19      michel   214487      834\n",
       "20     etienne   211297      898\n",
       "21   guillaume   197634      792\n",
       "22    claudine      280   163711\n",
       "23       andré   160970      586\n",
       "24        yves   156916      544\n",
       "25       henri   151366      504\n",
       "26  antoinette      326   150155"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prenoms.head(27)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: firstname, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "df_prenoms_with_space_or_hyphen = df_prenoms[df_prenoms['firstname'].str.contains(' |-', regex=True)]\n",
    "print(df_prenoms_with_space_or_hyphen['firstname'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6946, 3) (241, 4)\n"
     ]
    }
   ],
   "source": [
    "print(df_prenoms.shape , df_transcriptions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_line</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebb26ada-044c-4c62-9dbc-a9c8d505d31c</td>\n",
       "      <td>surname: Chardon firstname: Marie occupation: ...</td>\n",
       "      <td>nom: Chardon prénom: Marie date_naissance: 30 ...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338496f5-e4ca-43ac-aa5c-429cb3f6ac00</td>\n",
       "      <td>surname: Lhopital firstname: Louis-Jean occupa...</td>\n",
       "      <td>nom: Lhopital prénom: Louis Jean date_naissanc...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6a279da-9b6f-4f49-b498-64857bc50d1e</td>\n",
       "      <td>surname: Papin firstname: Marie occupation: id...</td>\n",
       "      <td>nom: Pyrin prénom: Marie date_naissance: 55 re...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7534deca-39e8-4f00-be17-c12460015de1</td>\n",
       "      <td>surname: Lavocat firstname: Marie link: femme ...</td>\n",
       "      <td>nom: Lavocat prénom: Marie date_naissance: 187...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ef334a66-a504-418a-9872-e7c9db923488</td>\n",
       "      <td>surname: Benne firstname: Marguerite age: 78</td>\n",
       "      <td>nom: Benne prénom: Marguerite date_naissance: ...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subject_line  \\\n",
       "0  ebb26ada-044c-4c62-9dbc-a9c8d505d31c   \n",
       "1  338496f5-e4ca-43ac-aa5c-429cb3f6ac00   \n",
       "2  e6a279da-9b6f-4f49-b498-64857bc50d1e   \n",
       "3  7534deca-39e8-4f00-be17-c12460015de1   \n",
       "4  ef334a66-a504-418a-9872-e7c9db923488   \n",
       "\n",
       "                                         groundtruth  \\\n",
       "0  surname: Chardon firstname: Marie occupation: ...   \n",
       "1  surname: Lhopital firstname: Louis-Jean occupa...   \n",
       "2  surname: Papin firstname: Marie occupation: id...   \n",
       "3  surname: Lavocat firstname: Marie link: femme ...   \n",
       "4      surname: Benne firstname: Marguerite age: 78    \n",
       "\n",
       "                                          prediction    sex  \n",
       "0  nom: Chardon prénom: Marie date_naissance: 30 ...  femme  \n",
       "1  nom: Lhopital prénom: Louis Jean date_naissanc...  homme  \n",
       "2  nom: Pyrin prénom: Marie date_naissance: 55 re...  femme  \n",
       "3  nom: Lavocat prénom: Marie date_naissance: 187...  femme  \n",
       "4  nom: Benne prénom: Marguerite date_naissance: ...  femme  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_line                                       ebb26ada-044c-4c62-9dbc-a9c8d505d31c\n",
       "groundtruth     surname: Chardon firstname: Marie occupation: idem link: fille age: 30 \n",
       "prediction            nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \" \n",
       "sex                                                                               femme\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Set the display option to print the entire line\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Print the first line of df_transcriptions\n",
    "df_transcriptions.iloc[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probalité des sexes des prénoms\n",
    "df_prenoms['total'] = df_prenoms['male'] + df_prenoms['female']\n",
    "df_prenoms['gender_probability'] = df_prenoms['female'] / df_prenoms['total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exctract first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def extract_firstname(text):\n",
    "    # Extraction du prénom à partir de la colonne groundtruth ou prediction\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in [\"firstname:\", \"prénom:\"]:\n",
    "            return parts[i+1]  # Retourne le prénom qui suit ces indicateurs\n",
    "    return None\n",
    "    '''\n",
    "\n",
    "def extract_firstname(text):\n",
    "    # Extraction du prénom à partir de la colonne groundtruth ou prediction\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part in [\"firstname:\", \"prénom:\"]:\n",
    "            firstname = parts[i+1]  # Retourne le prénom qui suit ces indicateurs\n",
    "            \n",
    "            # Check if the next part is also part of the first name\n",
    "            if i+2 < len(parts) and parts[i+2].isalpha():\n",
    "                firstname += \" \" + parts[i+2]\n",
    "            \n",
    "            return firstname\n",
    "    return None\n",
    "\n",
    "\n",
    "df_transcriptions['extracted_firstname_gt'] = df_transcriptions['groundtruth'].apply(extract_firstname)\n",
    "df_transcriptions['extracted_firstname_gt'] = df_transcriptions['extracted_firstname_gt'].str.lower()\n",
    "\n",
    "#\n",
    "df_transcriptions['extracted_firstname_pred'] = df_transcriptions['prediction'].apply(extract_firstname)  \n",
    "df_transcriptions['extracted_firstname_pred'] = df_transcriptions['extracted_firstname_pred'].str.lower()\n",
    "\n",
    "# Standardisation de la colonne 'sex' en binaire\n",
    "df_transcriptions['sex_binary'] = df_transcriptions['sex'].map({'femme': 1, 'homme': 0, 'ambigu': float('nan')})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "louis-jean louis jean\n",
      "antoine angène\n",
      "alexandre herandre\n",
      "marguerite oarguerite\n",
      "virginie vigmie\n",
      "eugènie eugénie\n",
      "josèphine joséphine\n",
      "anroine antoine\n",
      "justine gustine\n",
      "clément clement\n",
      "antoine angloise\n",
      "françois feris\n",
      "eugènie eugénie\n",
      "jacques jregues\n",
      "claude vaude\n",
      "jean-marie jean marie\n",
      "gilbert gilbeuse\n",
      "branislav branistau\n",
      "stanislas mamiolas\n",
      "None eugéne\n",
      "madeleine gadeleine\n",
      "etiennette ctiennette\n",
      "antoine aupène\n",
      "claude clause\n",
      "gilbert gilbeup\n",
      "pierre anne\n",
      "marthe marthy\n",
      "alix alice\n",
      "françoise faul\n",
      "françois antoine zean antoine\n",
      "antonie entonie\n",
      "jean-baptiste jean-haptiste\n",
      "jean-claude jean blanse\n",
      "victor vicher\n",
      "madeleine mareleine\n",
      "jean raymond jean-raymond\n",
      "france franco\n",
      "blaise clause\n",
      "baptiste bt\n",
      "simon simone\n",
      "marie-louise marie s\n",
      "madeleine vadeleine\n",
      "théodore théodote\n",
      "barthélémy barthe\n",
      "françois ferd\n",
      "pétronille gihromille\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(df_transcriptions)):\n",
    "    if df_transcriptions['extracted_firstname_gt'].iloc[i] != df_transcriptions['extracted_firstname_pred'].iloc[i]:\n",
    "        print(df_transcriptions['extracted_firstname_gt'].iloc[i], df_transcriptions['extracted_firstname_pred'].iloc[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_line</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sex</th>\n",
       "      <th>extracted_firstname_gt</th>\n",
       "      <th>extracted_firstname_pred</th>\n",
       "      <th>sex_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebb26ada-044c-4c62-9dbc-a9c8d505d31c</td>\n",
       "      <td>surname: Chardon firstname: Marie occupation: idem link: fille age: 30</td>\n",
       "      <td>nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \"</td>\n",
       "      <td>femme</td>\n",
       "      <td>marie</td>\n",
       "      <td>marie</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338496f5-e4ca-43ac-aa5c-429cb3f6ac00</td>\n",
       "      <td>surname: Lhopital firstname: Louis-Jean occupation: sp link: chef age: 67</td>\n",
       "      <td>nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef</td>\n",
       "      <td>homme</td>\n",
       "      <td>louis-jean</td>\n",
       "      <td>louis jean</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e6a279da-9b6f-4f49-b498-64857bc50d1e</td>\n",
       "      <td>surname: Papin firstname: Marie occupation: idem link: idem employer: idem age: 15</td>\n",
       "      <td>nom: Pyrin prénom: Marie date_naissance: 55 relation: d</td>\n",
       "      <td>femme</td>\n",
       "      <td>marie</td>\n",
       "      <td>marie</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subject_line  \\\n",
       "0  ebb26ada-044c-4c62-9dbc-a9c8d505d31c   \n",
       "1  338496f5-e4ca-43ac-aa5c-429cb3f6ac00   \n",
       "2  e6a279da-9b6f-4f49-b498-64857bc50d1e   \n",
       "\n",
       "                                                                           groundtruth  \\\n",
       "0              surname: Chardon firstname: Marie occupation: idem link: fille age: 30    \n",
       "1           surname: Lhopital firstname: Louis-Jean occupation: sp link: chef age: 67    \n",
       "2  surname: Papin firstname: Marie occupation: idem link: idem employer: idem age: 15    \n",
       "\n",
       "                                                                                 prediction  \\\n",
       "0                         nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \"    \n",
       "1  nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef    \n",
       "2                                  nom: Pyrin prénom: Marie date_naissance: 55 relation: d    \n",
       "\n",
       "     sex extracted_firstname_gt extracted_firstname_pred  sex_binary  \n",
       "0  femme                  marie                    marie         1.0  \n",
       "1  homme             louis-jean               louis jean         0.0  \n",
       "2  femme                  marie                    marie         1.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transcriptions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's exctract other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_occupation(text):\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part == \"occupation:\":\n",
    "            return parts[i+1]\n",
    "    return None\n",
    "\n",
    "def extract_link(text):\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part == \"link:\":\n",
    "            return parts[i+1]\n",
    "    return None\n",
    "\n",
    "def extract_profession(text):\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part == \"profession:\":\n",
    "            return parts[i+1]\n",
    "    return None\n",
    "\n",
    "def extract_relation(text):\n",
    "    parts = text.split()\n",
    "    for i, part in enumerate(parts):\n",
    "        if part == \"relation:\":\n",
    "            return parts[i+1]\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion basée sur les prénoms extraits\n",
    "df_combined = pd.merge(df_transcriptions,\n",
    "                       df_prenoms[['firstname', 'gender_probability']],\n",
    "                       left_on='extracted_firstname_gt',\n",
    "                       right_on='firstname',\n",
    "                       how='left')\n",
    "\n",
    "\n",
    "df_combined_pred = pd.merge(df_transcriptions,\n",
    "                       df_prenoms[['firstname', 'gender_probability']],\n",
    "                       left_on='extracted_firstname_pred',  # using predicted instead of groundtruth\n",
    "                       right_on='firstname',\n",
    "                       how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transcriptions['occupation'] = df_combined['groundtruth'].apply(extract_occupation)\n",
    "df_transcriptions['link'] = df_combined['groundtruth'].apply(extract_link)\n",
    "df_transcriptions['profession'] = df_combined_pred['prediction'].apply(extract_profession)\n",
    "df_transcriptions['relation'] = df_combined_pred['prediction'].apply(extract_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined['occupation'] = df_combined['groundtruth'].apply(extract_occupation)\n",
    "df_combined['link'] = df_combined['groundtruth'].apply(extract_link)\n",
    "df_combined_pred['profession'] = df_combined_pred['prediction'].apply(extract_profession)\n",
    "df_combined_pred['relation'] = df_combined_pred['prediction'].apply(extract_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_line</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>prediction</th>\n",
       "      <th>sex</th>\n",
       "      <th>extracted_firstname_gt</th>\n",
       "      <th>extracted_firstname_pred</th>\n",
       "      <th>sex_binary</th>\n",
       "      <th>firstname</th>\n",
       "      <th>gender_probability</th>\n",
       "      <th>occupation</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ebb26ada-044c-4c62-9dbc-a9c8d505d31c</td>\n",
       "      <td>surname: Chardon firstname: Marie occupation: idem link: fille age: 30</td>\n",
       "      <td>nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \"</td>\n",
       "      <td>femme</td>\n",
       "      <td>marie</td>\n",
       "      <td>marie</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marie</td>\n",
       "      <td>0.995774</td>\n",
       "      <td>idem</td>\n",
       "      <td>fille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>338496f5-e4ca-43ac-aa5c-429cb3f6ac00</td>\n",
       "      <td>surname: Lhopital firstname: Louis-Jean occupation: sp link: chef age: 67</td>\n",
       "      <td>nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef</td>\n",
       "      <td>homme</td>\n",
       "      <td>louis-jean</td>\n",
       "      <td>louis jean</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sp</td>\n",
       "      <td>chef</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subject_line  \\\n",
       "0  ebb26ada-044c-4c62-9dbc-a9c8d505d31c   \n",
       "1  338496f5-e4ca-43ac-aa5c-429cb3f6ac00   \n",
       "\n",
       "                                                                  groundtruth  \\\n",
       "0     surname: Chardon firstname: Marie occupation: idem link: fille age: 30    \n",
       "1  surname: Lhopital firstname: Louis-Jean occupation: sp link: chef age: 67    \n",
       "\n",
       "                                                                                 prediction  \\\n",
       "0                         nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \"    \n",
       "1  nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef    \n",
       "\n",
       "     sex extracted_firstname_gt extracted_firstname_pred  sex_binary  \\\n",
       "0  femme                  marie                    marie         1.0   \n",
       "1  homme             louis-jean               louis jean         0.0   \n",
       "\n",
       "  firstname  gender_probability occupation   link  \n",
       "0     marie            0.995774       idem  fille  \n",
       "1       NaN                 NaN         sp   chef  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['femme' 'homme' 'ambigu']\n"
     ]
    }
   ],
   "source": [
    "unique_sex_values = df_combined['sex'].unique()\n",
    "print(unique_sex_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex           ambigu  femme  homme\n",
      "link                              \n",
      "Chef             0.0    1.0    2.0\n",
      "Domestique       0.0    1.0    0.0\n",
      "Fils             0.0    0.0    1.0\n",
      "Leur             0.0    0.0    1.0\n",
      "Sa               0.0    2.0    0.0\n",
      "Schouer          0.0    1.0    0.0\n",
      "Son              0.0    0.0    1.0\n",
      "assisté          0.0    0.0    2.0\n",
      "belle-mère       0.0    3.0    0.0\n",
      "bru              0.0    3.0    0.0\n",
      "ch.              0.0    0.0    3.0\n",
      "chef             4.0    6.0   43.0\n",
      "domest.          0.0    1.0    0.0\n",
      "domestique       0.0    1.0    4.0\n",
      "enf              0.0    1.0    0.0\n",
      "enfant           1.0    9.0   13.0\n",
      "femme            0.0   20.0    0.0\n",
      "fille            0.0   13.0    0.0\n",
      "fils             0.0    0.0   18.0\n",
      "frère            0.0    0.0    2.0\n",
      "idem             4.0    8.0   17.0\n",
      "leur             0.0    1.0    5.0\n",
      "mère             0.0    4.0    0.0\n",
      "mére             0.0    1.0    0.0\n",
      "ouvrier          0.0    0.0    1.0\n",
      "pensionnaire     0.0    0.0    1.0\n",
      "petit-fils       0.0    0.0    2.0\n",
      "petite-fille     0.0    1.0    0.0\n",
      "père             0.0    0.0    2.0\n",
      "sa               0.0    5.0    0.0\n",
      "son              0.0    0.0    2.0\n",
      "ép               0.0    3.0    0.0\n",
      "épouse           0.0   16.0    0.0\n"
     ]
    }
   ],
   "source": [
    "link_counts = df_transcriptions.groupby('link')['sex'].value_counts().unstack().fillna(0)\n",
    "print(link_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex              ambigu  femme  homme\n",
      "occupation                           \n",
      "Cultivateur         0.0    0.0    1.0\n",
      "Domestique          0.0    1.0    0.0\n",
      "Garde               0.0    0.0    1.0\n",
      "Métayer             0.0    0.0    1.0\n",
      "Propriétaire        0.0    0.0    1.0\n",
      "Sans                0.0    1.0    0.0\n",
      "agent               0.0    0.0    1.0\n",
      "argentière          0.0    1.0    0.0\n",
      "blanchiseuse        0.0    1.0    0.0\n",
      "boulanger           0.0    1.0    0.0\n",
      "buraliste           0.0    0.0    1.0\n",
      "cantonnier          0.0    0.0    1.0\n",
      "charcutier          0.0    0.0    1.0\n",
      "charretier          0.0    0.0    1.0\n",
      "clerc               0.0    0.0    1.0\n",
      "coiffeur            0.0    0.0    1.0\n",
      "couturière          0.0    1.0    0.0\n",
      "couvreur            0.0    0.0    1.0\n",
      "culivateur          0.0    0.0    1.0\n",
      "cullotière          0.0    1.0    0.0\n",
      "cult                0.0    0.0    3.0\n",
      "cultiv              0.0    0.0    1.0\n",
      "cultivat            0.0    1.0    0.0\n",
      "cultivateur         1.0    0.0   12.0\n",
      "cultivatrice        0.0    0.0    1.0\n",
      "domest.             0.0    1.0    0.0\n",
      "domestique          0.0    4.0    5.0\n",
      "déposit             0.0    1.0    0.0\n",
      "employé             0.0    0.0    2.0\n",
      "employée            0.0    1.0    0.0\n",
      "femme               0.0    1.0    0.0\n",
      "forgeron            0.0    0.0    2.0\n",
      "garde               0.0    0.0    1.0\n",
      "garde-champêtre     0.0    0.0    1.0\n",
      "idem                6.0   23.0   25.0\n",
      "imprimeur           0.0    0.0    1.0\n",
      "jardinier           0.0    0.0    1.0\n",
      "journalier          1.0    0.0    3.0\n",
      "journalière         0.0    1.0    0.0\n",
      "manoeuvre           0.0    0.0    5.0\n",
      "menuisier           0.0    0.0    1.0\n",
      "métayer             0.0    0.0    5.0\n",
      "nourrisson          0.0    0.0    1.0\n",
      "néant               0.0   13.0    2.0\n",
      "ouvrier             0.0    0.0    2.0\n",
      "patissier           0.0    0.0    1.0\n",
      "propriétaire        0.0    1.0    0.0\n",
      "quincaillier        0.0    1.0    0.0\n",
      "receveur            0.0    0.0    1.0\n",
      "rentière            0.0    1.0    0.0\n",
      "repasseuse          0.0    1.0    0.0\n",
      "roulier             0.0    0.0    1.0\n",
      "s                   0.0    3.0    0.0\n",
      "s.p                 1.0    6.0    3.0\n",
      "s.p.                0.0    2.0    1.0\n",
      "sans                0.0   13.0    1.0\n",
      "sellier             0.0    0.0    1.0\n",
      "sp                  0.0    6.0    4.0\n",
      "tisserand           0.0    0.0    1.0\n",
      "tourneur            0.0    0.0    1.0\n",
      "voiturier           0.0    0.0    1.0\n"
     ]
    }
   ],
   "source": [
    "occupation_counts = df_transcriptions.groupby('occupation')['sex'].value_counts().unstack().fillna(0)\n",
    "print(occupation_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 37\n"
     ]
    }
   ],
   "source": [
    "# nombre de nan dans first name\n",
    "print(df_combined['firstname'].isna().sum(),df_combined_pred['firstname'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241, 11)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               male        female         total  gender_probability\n",
      "count  6.946000e+03  6.946000e+03  6.946000e+03         6946.000000\n",
      "mean   2.084710e+03  1.795356e+03  3.880067e+03            0.510974\n",
      "std    3.725168e+04  3.738858e+04  5.290102e+04            0.477295\n",
      "min    0.000000e+00  0.000000e+00  1.000000e+01            0.000000\n",
      "25%    0.000000e+00  0.000000e+00  1.600000e+01            0.000000\n",
      "50%    1.100000e+01  1.200000e+01  3.500000e+01            0.631579\n",
      "75%    4.000000e+01  4.300000e+01  1.450000e+02            1.000000\n",
      "max    1.869615e+06  2.390322e+06  2.400467e+06            1.000000\n",
      "Pourcentage de prénoms masculins: 53.73%\n",
      "Pourcentage de prénoms féminins: 46.27%\n"
     ]
    }
   ],
   "source": [
    "descriptive_stats = df_prenoms.describe()\n",
    "\n",
    "# Calcul de la répartition par genre\n",
    "total_male = df_prenoms['male'].sum()\n",
    "total_female = df_prenoms['female'].sum()\n",
    "total = total_male + total_female\n",
    "\n",
    "male_percentage = (total_male / total) * 100\n",
    "female_percentage = (total_female / total) * 100\n",
    "\n",
    "# Affichage des statistiques descriptives\n",
    "print(descriptive_stats)\n",
    "\n",
    "# Affichage de la répartition par genre\n",
    "print(f\"Pourcentage de prénoms masculins: {male_percentage:.2f}%\")\n",
    "print(f\"Pourcentage de prénoms féminins: {female_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14480397 12470545\n"
     ]
    }
   ],
   "source": [
    "print(total_male,total_female)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First predictions :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start with the clean data : using only the probability of the first name being in one gender (ground truth data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.9543568464730291\n"
     ]
    }
   ],
   "source": [
    "# Predict gender based on gender probability\n",
    "df_combined['predicted_gender_proba_only'] = df_combined['gender_probability'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = (df_combined['predicted_gender_proba_only'] == df_combined['sex_binary']).mean()\n",
    "print(\"Baseline accuracy:\", accuracy)\n",
    "\n",
    "# Accuracy is 0.975 with the baseline. It is a good results but we have to keep in mind that the data is clean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03734439834024896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_combined['sex_binary'].isna().sum()/len(df_combined))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now with predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.9045643153526971\n"
     ]
    }
   ],
   "source": [
    "# Predict gender based on gender probability\n",
    "df_combined_pred['predicted_gender_proba_only'] = df_combined_pred['gender_probability'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = (df_combined_pred['predicted_gender_proba_only'] == df_combined_pred['sex_binary']).mean()\n",
    "print(\"Baseline accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 90% accuraccy on the prediction data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.8049792531120332\n"
     ]
    }
   ],
   "source": [
    "# Predict gender based on gender probability\n",
    "df_combined_pred['predicted_gender_proba_only'] = df_combined_pred['gender_probability'].apply(lambda x: 1 if x > 0.5 else (0 if x <= 0.5 else x))\n",
    "# Compute accuracy\n",
    "accuracy = (df_combined_pred['predicted_gender_proba_only'] == df_combined_pred['sex_binary']).mean()\n",
    "print(\"Baseline accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's take into account the links and occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lists for male and female links and occupations\n",
    "male_links = ['Son', 'Fils', 'Père', 'Frère','Chef']\n",
    "female_links = ['Fille', 'Fils', 'Mère', 'Soeur']\n",
    "#male_occupations = ['Chef'] # men were the only chef of the house at the time of the dataset\n",
    "#female_occupations = ['Femme']\n",
    "\n",
    "# Define a function to determine the predicted gender based on link and occupation\n",
    "def predict_gender_gt(row):\n",
    "    if row['link'] in male_links:\n",
    "        return 0\n",
    "    elif row['link'] in female_links:\n",
    "        return 1\n",
    "#    elif row['occupation'] in male_occupations:\n",
    "#        return 0\n",
    "#    elif row['occupation'] in female_occupations:\n",
    "#        return 1\n",
    "    else:\n",
    "        return 1 if row['gender_probability'] > 0.5 else 0\n",
    "    \n",
    "def predict_gender_pred(row):\n",
    "    if row['relation'] in male_links:\n",
    "        return 0\n",
    "    elif row['relation'] in female_links:\n",
    "        return 1\n",
    "#    elif row['profession'] in male_occupations:\n",
    "#        return 0\n",
    "#    elif row['profession'] in female_occupations:\n",
    "#        return 1\n",
    "    else:\n",
    "        return 1 if row['gender_probability'] > 0.5 else 0    \n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to create the predicted_gender_all_data column\n",
    "df_combined['predicted_gender_all_data'] = df_combined.apply(predict_gender_gt, axis=1)\n",
    "df_combined_pred['predicted_gender_all_data'] = df_combined_pred.apply(predict_gender_pred, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9004149377593361\n"
     ]
    }
   ],
   "source": [
    "accuracy = (df_combined_pred['predicted_gender_all_data'] == df_combined_pred['sex_binary']).mean()\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "#Accuracy of 0.90% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try NLP models ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero shot prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero shot on ground truth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/facebook/bart-large-mnli/cfbb687dbbd9df99fe865e1860350a22aebac4d26ee4bcb50217f1df606a018e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1712580526&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjU4MDUyNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9mYWNlYm9vay9iYXJ0LWxhcmdlLW1ubGkvY2ZiYjY4N2RiYmQ5ZGY5OWZlODY1ZTE4NjAzNTBhMjJhZWJhYzRkMjZlZTRiY2I1MDIxN2YxZGY2MDZhMDE4ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=hiTC6XAVmspAo9BeEaFG0kBxjbMieLCIVOBQw4au3XiRi%7EYHlsVNt37hRH7PXZneMDgj1tQP33hNkyxePSBnygWd3Kh8aytfiTYBYuJ5SzrzJI6Syr-jSr5YeM5O0AYC2Gw7XIrlrR43%7Er-ew0LJoU9rlBMZZBhWZS%7E1mq5IcTvvS65q0XlN9togrd-Ek5WSFqfCdEFyNUR7ycRc0Mnk4PABaeuM944J6nOYUpau-hN6xHayQ7-ZResYp%7EwAk6pACmmpX9iXxMMbNk7NdWc6nN01UCkQoK98nduTCnk8vNXrAHpV5mGEYjgJsd%7EWHzaK1J5nr%7EKBCK9lkhtbK0uK7Q__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://cdn-lfs.huggingface.co/facebook/bart-large-mnli/cfbb687dbbd9df99fe865e1860350a22aebac4d26ee4bcb50217f1df606a018e?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1712583406&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcxMjU4MzQwNn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9mYWNlYm9vay9iYXJ0LWxhcmdlLW1ubGkvY2ZiYjY4N2RiYmQ5ZGY5OWZlODY1ZTE4NjAzNTBhMjJhZWJhYzRkMjZlZTRiY2I1MDIxN2YxZGY2MDZhMDE4ZT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=vI67kec9cRWvC-2B3UHQznDDGWBn6N367Tl1%7EUMVa8GUT0575UQFsfJlRk5KWbzOnYK%7EN%7E7OrtWVj-pj%7EJBmvrxqzS9F80mZrJ2UmszEgcjILS6kn3dBUvgETiRr5qljwuzfiDOm9etD8Y4tElM7sIDruCm%7ENZoeI0stO1kMW5BRiKsZCk13TtK2kV08%7EZ8QGvEEON9CsgzPkYvasAqSS2BQxiwvybK5mPD4BkCGhcdXK8ctNfWSJZjTr5xDa09MwZyj9sbsrdBQwvrskWz5XmrNiXiO3dGBN7pR8BDgUDo8EYXA%7EdLnHWH3WYcnMu0Ce-aF4noTKzfvZdKVbYfAzQ__&Key-Pair-Id=KVTP0A1DKRTAX: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-mnli and are newly initialized: ['model.decoder.embed_tokens.weight', 'model.encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "''' can be long to run\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Define candidate labels\n",
    "labels = [\"male\", \"female\"]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for text in df_combined['groundtruth']:\n",
    "    # Predict the label of the text\n",
    "    result = classifier(text, labels)\n",
    "    # Get the label with the highest score\n",
    "    predicted_label = result[\"labels\"][result[\"scores\"].index(max(result[\"scores\"]))]\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "df_combined['predicted_sex_zero_shot'] = predictions\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9377593360995851"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "df_combined['predicted_sex_zero_shot_binary'] = df_combined['predicted_sex_zero_shot'].apply(lambda x: 1 if x == 'female' else 0)\n",
    "\n",
    "accuracy_zero_shot = (df_combined['predicted_sex_zero_shot_binary'] == df_combined['sex_binary']).mean()\n",
    "accuracy_zero_shot\n",
    "\n",
    "# 0.937759% accuracy with zero shot classification\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-large-mnli and are newly initialized: ['model.decoder.embed_tokens.weight', 'model.encoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Define candidate labels\n",
    "labels = [\"male\", \"female\"]\n",
    "\n",
    "\n",
    "predictions = []\n",
    "for text in df_combined['prediction']:\n",
    "    # Predict the label of the text\n",
    "    result = classifier(text, labels)\n",
    "    # Get the label with the highest score\n",
    "    predicted_label = result[\"labels\"][result[\"scores\"].index(max(result[\"scores\"]))]\n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "# Add predictions to DataFrame\n",
    "df_combined_pred['predicted_sex_zero_shot'] = predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8672199170124482"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined_pred['predicted_sex_zero_shot_binary'] = df_combined_pred['predicted_sex_zero_shot'].apply(lambda x: 1 if x == 'female' else 0)\n",
    "\n",
    "accuracy_zero_shot = (df_combined_pred['predicted_sex_zero_shot_binary'] == df_combined['sex_binary']).mean()\n",
    "accuracy_zero_shot\n",
    "\n",
    "#accuracy of 0.8672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.995774\n",
       "1           NaN\n",
       "2      0.995774\n",
       "3      0.995774\n",
       "4      0.998233\n",
       "         ...   \n",
       "236    0.997709\n",
       "237    0.004556\n",
       "238    0.998233\n",
       "239    0.004232\n",
       "240    0.997834\n",
       "Name: gender_probability, Length: 241, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['gender_probability']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model on cases that are impossible for the rule-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when probability is NaN: 0.6486486486486487\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to include only rows where the probability column is NaN\n",
    "df_filtered = df_combined_pred[df_combined_pred['gender_probability'].isna()]\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = (df_filtered['predicted_gender_all_data'] == df_filtered['sex_binary']).mean()\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy when probability is NaN:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 13)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First try with basic settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenisation et préparation des données pour le modèle\n",
    "class GenderPredictionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        labels = self.labels[idx]\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        \n",
    "        # Important: Convert 'BatchEncoding' to a more usable format\n",
    "        input_ids = encoding['input_ids'].squeeze()  # Remove batch dimension\n",
    "        attention_mask = encoding['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': torch.tensor(labels)}\n",
    "\n",
    "# Preparation des données\n",
    "texts = df_combined['prediction'].tolist()\n",
    "labels = df_combined['sex_binary'].tolist()\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = GenderPredictionDataset(texts_train, labels_train, tokenizer)\n",
    "test_dataset = GenderPredictionDataset(texts_test, labels_test, tokenizer)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 192\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 72\n",
      "  Number of trainable parameters = 66955010\n",
      " 33%|███▎      | 24/72 [01:23<02:44,  3.44s/it]***** Running Evaluation *****\n",
      "  Num examples = 49\n",
      "  Batch size = 8\n",
      "                                               \n",
      " 33%|███▎      | 24/72 [01:29<02:44,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6939376592636108, 'eval_runtime': 5.6103, 'eval_samples_per_second': 8.734, 'eval_steps_per_second': 1.248, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 48/72 [02:51<01:22,  3.43s/it]***** Running Evaluation *****\n",
      "  Num examples = 49\n",
      "  Batch size = 8\n",
      "                                               \n",
      " 67%|██████▋   | 48/72 [02:57<01:22,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6911244988441467, 'eval_runtime': 5.6169, 'eval_samples_per_second': 8.724, 'eval_steps_per_second': 1.246, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [04:21<00:00,  3.53s/it]***** Running Evaluation *****\n",
      "  Num examples = 49\n",
      "  Batch size = 8\n",
      "                                               \n",
      "100%|██████████| 72/72 [04:26<00:00,  3.53s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 72/72 [04:26<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6831199526786804, 'eval_runtime': 5.6784, 'eval_samples_per_second': 8.629, 'eval_steps_per_second': 1.233, 'epoch': 3.0}\n",
      "{'train_runtime': 266.9419, 'train_samples_per_second': 2.158, 'train_steps_per_second': 0.27, 'train_loss': 0.6858603689405653, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=72, training_loss=0.6858603689405653, metrics={'train_runtime': 266.9419, 'train_samples_per_second': 2.158, 'train_steps_per_second': 0.27, 'train_loss': 0.6858603689405653, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 49\n",
      "  Batch size = 8\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6831199526786804, 'eval_runtime': 5.811, 'eval_samples_per_second': 8.432, 'eval_steps_per_second': 1.205, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "evaluation_results = trainer.evaluate(test_dataset)\n",
    "print(evaluation_results)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 49\n",
      "  Batch size = 8\n",
      "100%|██████████| 7/7 [00:04<00:00,  1.47it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your test labels and predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "cm = confusion_matrix(labels_test, predicted_labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_no_nan = df_combined.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Tokenisation et préparation des données pour le modèle\n",
    "class GenderPredictionDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = int(self.labels[idx])  # Convert label to integer\n",
    "        encoding = self.tokenizer(text, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "        \n",
    "        # Convert label to one-hot encoding\n",
    "        label_one_hot = torch.zeros(2)\n",
    "        label_one_hot[label] = 1\n",
    "\n",
    "        # Important: Convert 'BatchEncoding' to a more usable format\n",
    "        input_ids = encoding['input_ids'].squeeze()  # Remove batch dimension\n",
    "        attention_mask = encoding['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': label_one_hot}\n",
    "\n",
    "# Preparation des données\n",
    "texts = df_combined_no_nan['prediction'].tolist()\n",
    "labels = df_combined_no_nan['sex_binary'].tolist()\n",
    "\n",
    "# Division en ensembles d'entraînement et de test\n",
    "texts_train, texts_test, labels_train, labels_test = train_test_split(texts, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = GenderPredictionDataset(texts_train, labels_train, tokenizer)\n",
    "test_dataset = GenderPredictionDataset(texts_test, labels_test, tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 200\n",
      "  Number of trainable parameters = 66955010\n",
      " 10%|█         | 20/200 [01:05<07:36,  2.53s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 10%|█         | 20/200 [01:07<07:36,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7040766477584839, 'eval_runtime': 1.952, 'eval_samples_per_second': 9.221, 'eval_steps_per_second': 1.537, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [02:12<06:44,  2.53s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 20%|██        | 40/200 [02:14<06:44,  2.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7040635347366333, 'eval_runtime': 1.9309, 'eval_samples_per_second': 9.322, 'eval_steps_per_second': 1.554, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [03:20<06:02,  2.59s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 30%|███       | 60/200 [03:22<06:02,  2.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7057966589927673, 'eval_runtime': 1.9907, 'eval_samples_per_second': 9.042, 'eval_steps_per_second': 1.507, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 80/200 [04:29<05:17,  2.65s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 40%|████      | 80/200 [04:31<05:17,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7064812779426575, 'eval_runtime': 2.0379, 'eval_samples_per_second': 8.833, 'eval_steps_per_second': 1.472, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 100/200 [05:39<04:23,  2.64s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 50%|█████     | 100/200 [05:41<04:23,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.705090343952179, 'eval_runtime': 2.0305, 'eval_samples_per_second': 8.865, 'eval_steps_per_second': 1.477, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 120/200 [06:49<03:33,  2.67s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 60%|██████    | 120/200 [06:51<03:33,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6955525875091553, 'eval_runtime': 2.0581, 'eval_samples_per_second': 8.746, 'eval_steps_per_second': 1.458, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 140/200 [08:00<02:39,  2.66s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 70%|███████   | 140/200 [08:02<02:39,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6962171196937561, 'eval_runtime': 2.0671, 'eval_samples_per_second': 8.708, 'eval_steps_per_second': 1.451, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 160/200 [09:11<01:46,  2.67s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 80%|████████  | 160/200 [09:13<01:46,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6626589298248291, 'eval_runtime': 2.097, 'eval_samples_per_second': 8.584, 'eval_steps_per_second': 1.431, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 180/200 [10:22<00:53,  2.68s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 90%|█████████ | 180/200 [10:24<00:53,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.54349684715271, 'eval_runtime': 2.0783, 'eval_samples_per_second': 8.661, 'eval_steps_per_second': 1.443, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [11:33<00:00,  2.68s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "100%|██████████| 200/200 [11:35<00:00,  2.68s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 200/200 [11:35<00:00,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43833765387535095, 'eval_runtime': 2.0713, 'eval_samples_per_second': 8.69, 'eval_steps_per_second': 1.448, 'epoch': 10.0}\n",
      "{'train_runtime': 695.2136, 'train_samples_per_second': 2.201, 'train_steps_per_second': 0.288, 'train_loss': 0.6505979919433593, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.6505979919433593, metrics={'train_runtime': 695.2136, 'train_samples_per_second': 2.201, 'train_steps_per_second': 0.288, 'train_loss': 0.6505979919433593, 'epoch': 10.0})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from transformers import AdamW\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=1            #1e-5  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    optimizers=(AdamW(model.parameters(), lr=1e-5), None)  # Use AdamW optimizer\n",
    ")\n",
    "\n",
    "trainer.train()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/6cdc0aad91f5ae2e6712e91bc7b65d1cf5c05411/model.safetensors\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 153\n",
      "  Num Epochs = 40\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 800\n",
      "  Number of trainable parameters = 66955010\n",
      "  2%|▎         | 20/800 [01:06<33:13,  2.56s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "  2%|▎         | 20/800 [01:08<33:13,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7167547941207886, 'eval_runtime': 1.9542, 'eval_samples_per_second': 9.211, 'eval_steps_per_second': 1.535, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 40/800 [02:15<33:29,  2.64s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "  5%|▌         | 40/800 [02:18<33:29,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7162106037139893, 'eval_runtime': 2.0549, 'eval_samples_per_second': 8.76, 'eval_steps_per_second': 1.46, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 60/800 [03:27<34:13,  2.78s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "  8%|▊         | 60/800 [03:29<34:13,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7180238962173462, 'eval_runtime': 2.218, 'eval_samples_per_second': 8.115, 'eval_steps_per_second': 1.353, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 80/800 [04:40<33:31,  2.79s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 10%|█         | 80/800 [04:42<33:31,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7172243595123291, 'eval_runtime': 2.0801, 'eval_samples_per_second': 8.653, 'eval_steps_per_second': 1.442, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 100/800 [05:52<31:24,  2.69s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 12%|█▎        | 100/800 [05:54<31:24,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7126942873001099, 'eval_runtime': 2.093, 'eval_samples_per_second': 8.6, 'eval_steps_per_second': 1.433, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 120/800 [07:03<30:34,  2.70s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 15%|█▌        | 120/800 [07:05<30:34,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7018867135047913, 'eval_runtime': 2.078, 'eval_samples_per_second': 8.662, 'eval_steps_per_second': 1.444, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 140/800 [08:14<29:46,  2.71s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 18%|█▊        | 140/800 [08:16<29:46,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7050731182098389, 'eval_runtime': 2.1041, 'eval_samples_per_second': 8.555, 'eval_steps_per_second': 1.426, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 160/800 [09:27<28:39,  2.69s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 20%|██        | 160/800 [09:29<28:39,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.677053689956665, 'eval_runtime': 2.11, 'eval_samples_per_second': 8.531, 'eval_steps_per_second': 1.422, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 180/800 [10:38<27:58,  2.71s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 22%|██▎       | 180/800 [10:40<27:58,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.599799394607544, 'eval_runtime': 2.1224, 'eval_samples_per_second': 8.481, 'eval_steps_per_second': 1.414, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 200/800 [11:50<27:06,  2.71s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 25%|██▌       | 200/800 [11:52<27:06,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4863348603248596, 'eval_runtime': 2.1053, 'eval_samples_per_second': 8.55, 'eval_steps_per_second': 1.425, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 220/800 [13:02<26:08,  2.70s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 28%|██▊       | 220/800 [13:04<26:08,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40958163142204285, 'eval_runtime': 2.1101, 'eval_samples_per_second': 8.531, 'eval_steps_per_second': 1.422, 'epoch': 11.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 240/800 [14:13<25:10,  2.70s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 30%|███       | 240/800 [14:16<25:10,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3511832058429718, 'eval_runtime': 2.0977, 'eval_samples_per_second': 8.581, 'eval_steps_per_second': 1.43, 'epoch': 12.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 260/800 [15:26<24:24,  2.71s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 32%|███▎      | 260/800 [15:28<24:24,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28498753905296326, 'eval_runtime': 2.1312, 'eval_samples_per_second': 8.446, 'eval_steps_per_second': 1.408, 'epoch': 13.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 280/800 [16:38<23:38,  2.73s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 35%|███▌      | 280/800 [16:40<23:38,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27359867095947266, 'eval_runtime': 2.1352, 'eval_samples_per_second': 8.43, 'eval_steps_per_second': 1.405, 'epoch': 14.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 300/800 [17:50<22:39,  2.72s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 38%|███▊      | 300/800 [17:52<22:39,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24379508197307587, 'eval_runtime': 2.1255, 'eval_samples_per_second': 8.469, 'eval_steps_per_second': 1.411, 'epoch': 15.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 320/800 [19:02<21:46,  2.72s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 40%|████      | 320/800 [19:04<21:46,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22216421365737915, 'eval_runtime': 2.1254, 'eval_samples_per_second': 8.469, 'eval_steps_per_second': 1.411, 'epoch': 16.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▎     | 340/800 [20:15<21:02,  2.74s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 42%|████▎     | 340/800 [20:17<21:02,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25499045848846436, 'eval_runtime': 2.1599, 'eval_samples_per_second': 8.334, 'eval_steps_per_second': 1.389, 'epoch': 17.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 360/800 [21:28<20:02,  2.73s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 45%|████▌     | 360/800 [21:30<20:02,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23757094144821167, 'eval_runtime': 2.1615, 'eval_samples_per_second': 8.328, 'eval_steps_per_second': 1.388, 'epoch': 18.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 380/800 [22:40<19:10,  2.74s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 48%|████▊     | 380/800 [22:42<19:10,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24088886380195618, 'eval_runtime': 2.1336, 'eval_samples_per_second': 8.437, 'eval_steps_per_second': 1.406, 'epoch': 19.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 400/800 [23:56<19:44,  2.96s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 50%|█████     | 400/800 [23:58<19:44,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23501703143119812, 'eval_runtime': 2.1337, 'eval_samples_per_second': 8.436, 'eval_steps_per_second': 1.406, 'epoch': 20.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▎    | 420/800 [25:11<17:50,  2.82s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 52%|█████▎    | 420/800 [25:14<17:50,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24698257446289062, 'eval_runtime': 2.2495, 'eval_samples_per_second': 8.002, 'eval_steps_per_second': 1.334, 'epoch': 21.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 440/800 [26:26<16:29,  2.75s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 55%|█████▌    | 440/800 [26:28<16:29,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2517710328102112, 'eval_runtime': 2.1113, 'eval_samples_per_second': 8.526, 'eval_steps_per_second': 1.421, 'epoch': 22.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▊    | 460/800 [27:39<15:39,  2.76s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 57%|█████▊    | 460/800 [27:41<15:39,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3935675323009491, 'eval_runtime': 2.1076, 'eval_samples_per_second': 8.541, 'eval_steps_per_second': 1.423, 'epoch': 23.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 480/800 [28:53<14:52,  2.79s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 60%|██████    | 480/800 [28:55<14:52,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26184654235839844, 'eval_runtime': 2.2029, 'eval_samples_per_second': 8.171, 'eval_steps_per_second': 1.362, 'epoch': 24.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 500/800 [30:06<13:37,  2.72s/it]Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3376, 'learning_rate': 1e-05, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 62%|██████▎   | 500/800 [30:09<13:37,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27712732553482056, 'eval_runtime': 2.2885, 'eval_samples_per_second': 7.865, 'eval_steps_per_second': 1.311, 'epoch': 25.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 520/800 [31:22<13:03,  2.80s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 65%|██████▌   | 520/800 [31:24<13:03,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27706262469291687, 'eval_runtime': 2.161, 'eval_samples_per_second': 8.33, 'eval_steps_per_second': 1.388, 'epoch': 26.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 540/800 [32:36<11:56,  2.76s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 68%|██████▊   | 540/800 [32:38<11:56,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27701297402381897, 'eval_runtime': 2.1459, 'eval_samples_per_second': 8.388, 'eval_steps_per_second': 1.398, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 560/800 [33:49<11:12,  2.80s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 70%|███████   | 560/800 [33:52<11:12,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31513944268226624, 'eval_runtime': 2.4606, 'eval_samples_per_second': 7.315, 'eval_steps_per_second': 1.219, 'epoch': 28.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▎  | 580/800 [35:03<10:01,  2.74s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 72%|███████▎  | 580/800 [35:05<10:01,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.33124208450317383, 'eval_runtime': 2.127, 'eval_samples_per_second': 8.463, 'eval_steps_per_second': 1.41, 'epoch': 29.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 600/800 [36:15<09:04,  2.72s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 75%|███████▌  | 600/800 [36:17<09:04,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28682729601860046, 'eval_runtime': 2.0937, 'eval_samples_per_second': 8.597, 'eval_steps_per_second': 1.433, 'epoch': 30.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 620/800 [37:28<08:16,  2.76s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 78%|███████▊  | 620/800 [37:30<08:16,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2877143919467926, 'eval_runtime': 2.1142, 'eval_samples_per_second': 8.514, 'eval_steps_per_second': 1.419, 'epoch': 31.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 640/800 [38:40<07:15,  2.72s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 80%|████████  | 640/800 [38:42<07:15,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2940234839916229, 'eval_runtime': 2.1117, 'eval_samples_per_second': 8.524, 'eval_steps_per_second': 1.421, 'epoch': 32.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▎ | 660/800 [39:52<06:25,  2.76s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 82%|████████▎ | 660/800 [39:54<06:25,  2.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29434478282928467, 'eval_runtime': 2.1252, 'eval_samples_per_second': 8.47, 'eval_steps_per_second': 1.412, 'epoch': 33.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 680/800 [41:08<05:47,  2.89s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 85%|████████▌ | 680/800 [41:10<05:47,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2956094741821289, 'eval_runtime': 2.1404, 'eval_samples_per_second': 8.41, 'eval_steps_per_second': 1.402, 'epoch': 34.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 700/800 [42:24<04:45,  2.85s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 88%|████████▊ | 700/800 [42:26<04:45,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29744240641593933, 'eval_runtime': 2.1584, 'eval_samples_per_second': 8.339, 'eval_steps_per_second': 1.39, 'epoch': 35.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 720/800 [43:39<03:44,  2.81s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 90%|█████████ | 720/800 [43:41<03:44,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.298817902803421, 'eval_runtime': 2.1098, 'eval_samples_per_second': 8.532, 'eval_steps_per_second': 1.422, 'epoch': 36.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▎| 740/800 [44:55<02:53,  2.90s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 92%|█████████▎| 740/800 [44:57<02:53,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3009965419769287, 'eval_runtime': 2.1557, 'eval_samples_per_second': 8.35, 'eval_steps_per_second': 1.392, 'epoch': 37.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 760/800 [46:11<01:53,  2.85s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 95%|█████████▌| 760/800 [46:13<01:53,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30175095796585083, 'eval_runtime': 2.1069, 'eval_samples_per_second': 8.544, 'eval_steps_per_second': 1.424, 'epoch': 38.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 780/800 [47:26<00:58,  2.90s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      " 98%|█████████▊| 780/800 [47:28<00:58,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3022264838218689, 'eval_runtime': 2.1993, 'eval_samples_per_second': 8.184, 'eval_steps_per_second': 1.364, 'epoch': 39.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [48:42<00:00,  2.92s/it]***** Running Evaluation *****\n",
      "  Num examples = 18\n",
      "  Batch size = 8\n",
      "\n",
      "100%|██████████| 800/800 [48:44<00:00,  2.92s/it]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 800/800 [48:44<00:00,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30253615975379944, 'eval_runtime': 2.2613, 'eval_samples_per_second': 7.96, 'eval_steps_per_second': 1.327, 'epoch': 40.0}\n",
      "{'train_runtime': 2924.5819, 'train_samples_per_second': 2.093, 'train_steps_per_second': 0.274, 'train_loss': 0.21434829950332643, 'epoch': 40.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=0.21434829950332643, metrics={'train_runtime': 2924.5819, 'train_samples_per_second': 2.093, 'train_steps_per_second': 0.274, 'train_loss': 0.21434829950332643, 'epoch': 40.0})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=40,  # Increase the number of epochs\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='epoch',\n",
    "    learning_rate=1            #1e-5  \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    optimizers=(AdamW(model.parameters(), lr=1e-5), None)  # Use AdamW optimizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 86\n",
      "  Batch size = 8\n",
      "100%|██████████| 11/11 [00:08<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6905139088630676, 'eval_runtime': 9.1998, 'eval_samples_per_second': 9.348, 'eval_steps_per_second': 1.196, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate(test_dataset)\n",
    "print(evaluation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 86\n",
      "  Batch size = 8\n",
      "100%|██████████| 11/11 [00:08<00:00,  1.32it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have your test labels and predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "predicted_labels = predictions.predictions.argmax(axis=0)\n",
    "\n",
    "own_predicted_labels = np.where(predictions.predictions[:, 0] > predictions.predictions[:, 1], 0, 1)\n",
    "\n",
    "#np.where(predictions[:, 0] > predictions[:, 1], 0, 1)\n",
    "\n",
    "cm = confusion_matrix(labels_test, own_predicted_labels)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 0.0566771 , -0.12524076],\n",
       "       [ 0.04752814, -0.12315789],\n",
       "       [ 0.04366241, -0.11462161],\n",
       "       [ 0.02112989, -0.10037215],\n",
       "       [ 0.02026314, -0.12774222],\n",
       "       [ 0.02220481, -0.11194923],\n",
       "       [ 0.05643402, -0.13002206],\n",
       "       [ 0.01411365, -0.08720087],\n",
       "       [ 0.0369511 , -0.12645443],\n",
       "       [ 0.0503949 , -0.12213787],\n",
       "       [ 0.04924645, -0.13357215],\n",
       "       [ 0.03940484, -0.10200471],\n",
       "       [ 0.03024988, -0.09457487],\n",
       "       [ 0.050217  , -0.10544784],\n",
       "       [ 0.03892333, -0.11274492],\n",
       "       [ 0.03226397, -0.11662194],\n",
       "       [ 0.04351426, -0.12185172],\n",
       "       [ 0.09580768, -0.1620226 ],\n",
       "       [ 0.01259565, -0.11248206],\n",
       "       [ 0.08627535, -0.17541434],\n",
       "       [ 0.02716439, -0.1141671 ],\n",
       "       [ 0.09822515, -0.15919733],\n",
       "       [ 0.04198007, -0.13780633],\n",
       "       [ 0.04222915, -0.12492218],\n",
       "       [ 0.05762249, -0.14962041],\n",
       "       [ 0.06804344, -0.16792575],\n",
       "       [ 0.02532768, -0.10642483],\n",
       "       [ 0.04279068, -0.08998768],\n",
       "       [ 0.02120831, -0.13065398],\n",
       "       [ 0.11160147, -0.17903996],\n",
       "       [ 0.02708555, -0.11863488],\n",
       "       [ 0.03960221, -0.1199436 ],\n",
       "       [ 0.03754231, -0.11120886],\n",
       "       [ 0.03985202, -0.12539521],\n",
       "       [ 0.11778298, -0.17123027],\n",
       "       [ 0.03681048, -0.11135669],\n",
       "       [ 0.0368077 , -0.10808071],\n",
       "       [ 0.11578408, -0.15847155],\n",
       "       [ 0.03637894, -0.10999817],\n",
       "       [ 0.05519015, -0.12930825],\n",
       "       [ 0.09225876, -0.15262857],\n",
       "       [ 0.02905183, -0.12540135],\n",
       "       [ 0.06219855, -0.12244506],\n",
       "       [ 0.11177991, -0.17585473],\n",
       "       [ 0.04268105, -0.13164142],\n",
       "       [ 0.10820043, -0.16040511],\n",
       "       [ 0.04666714, -0.10816229],\n",
       "       [ 0.03242575, -0.1434196 ],\n",
       "       [ 0.05279417, -0.13403271],\n",
       "       [ 0.06002424, -0.11280439],\n",
       "       [ 0.04127077, -0.10982374],\n",
       "       [ 0.06328533, -0.13397664],\n",
       "       [ 0.08172614, -0.1589101 ],\n",
       "       [ 0.01635023, -0.10974423],\n",
       "       [ 0.01655855, -0.11613867],\n",
       "       [ 0.04413631, -0.13695762],\n",
       "       [ 0.06948414, -0.12865728],\n",
       "       [ 0.03831322, -0.10538798],\n",
       "       [ 0.02688637, -0.11339921],\n",
       "       [ 0.04296066, -0.09826966],\n",
       "       [ 0.0546842 , -0.11868554],\n",
       "       [ 0.05029958, -0.11302283],\n",
       "       [ 0.03785275, -0.11818835],\n",
       "       [ 0.02988575, -0.12045745],\n",
       "       [ 0.0267709 , -0.09984586],\n",
       "       [ 0.04296864, -0.12843688],\n",
       "       [ 0.01452679, -0.13026279],\n",
       "       [ 0.1015286 , -0.1828032 ],\n",
       "       [ 0.0200445 , -0.11565495],\n",
       "       [ 0.04737542, -0.11625639],\n",
       "       [ 0.0154954 , -0.11944341],\n",
       "       [ 0.03774824, -0.09380858],\n",
       "       [ 0.04231045, -0.09808302],\n",
       "       [ 0.04475853, -0.11804164],\n",
       "       [ 0.04034428, -0.12564911],\n",
       "       [ 0.04296793, -0.13825817],\n",
       "       [ 0.0226472 , -0.13669203],\n",
       "       [ 0.10060477, -0.16408296],\n",
       "       [ 0.02521191, -0.12867366],\n",
       "       [ 0.03947714, -0.11067064],\n",
       "       [ 0.03218246, -0.12129091],\n",
       "       [ 0.04889575, -0.10651942],\n",
       "       [ 0.03062833, -0.12317318],\n",
       "       [ 0.05607816, -0.11037157],\n",
       "       [ 0.05790499, -0.1299219 ],\n",
       "       [ 0.04471047, -0.11478569]], dtype=float32), label_ids=array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.]], dtype=float32), metrics={'test_loss': 0.6905139088630676, 'test_runtime': 9.2682, 'test_samples_per_second': 9.279, 'test_steps_per_second': 1.187})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43 76]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert few-shot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: requests in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: filelock in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: torch in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (2.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: networkx in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: filelock in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: sympy in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading file vocab.txt from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=512,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      0.0\n",
       "2      1.0\n",
       "3      1.0\n",
       "4      1.0\n",
       "5      0.0\n",
       "6      0.0\n",
       "7      0.0\n",
       "8      1.0\n",
       "9      1.0\n",
       "10     0.0\n",
       "11     1.0\n",
       "12     1.0\n",
       "13     1.0\n",
       "14     0.0\n",
       "15     0.0\n",
       "16     1.0\n",
       "17     NaN\n",
       "18     0.0\n",
       "19     1.0\n",
       "20     1.0\n",
       "21     0.0\n",
       "22     1.0\n",
       "23     1.0\n",
       "24     0.0\n",
       "25     1.0\n",
       "26     0.0\n",
       "27     1.0\n",
       "28     0.0\n",
       "29     0.0\n",
       "30     0.0\n",
       "31     1.0\n",
       "32     0.0\n",
       "33     0.0\n",
       "34     1.0\n",
       "35     0.0\n",
       "36     0.0\n",
       "37     1.0\n",
       "38     0.0\n",
       "39     1.0\n",
       "40     1.0\n",
       "41     1.0\n",
       "42     1.0\n",
       "43     0.0\n",
       "44     0.0\n",
       "45     1.0\n",
       "46     0.0\n",
       "47     1.0\n",
       "48     1.0\n",
       "49     0.0\n",
       "50     0.0\n",
       "51     1.0\n",
       "52     0.0\n",
       "53     1.0\n",
       "54     1.0\n",
       "55     1.0\n",
       "56     1.0\n",
       "57     1.0\n",
       "58     0.0\n",
       "59     NaN\n",
       "60     0.0\n",
       "61     1.0\n",
       "62     0.0\n",
       "63     0.0\n",
       "64     1.0\n",
       "65     0.0\n",
       "66     1.0\n",
       "67     1.0\n",
       "68     1.0\n",
       "69     0.0\n",
       "70     0.0\n",
       "71     1.0\n",
       "72     0.0\n",
       "73     0.0\n",
       "74     1.0\n",
       "75     0.0\n",
       "76     0.0\n",
       "77     1.0\n",
       "78     1.0\n",
       "79     1.0\n",
       "80     1.0\n",
       "81     1.0\n",
       "82     0.0\n",
       "83     0.0\n",
       "84     0.0\n",
       "85     0.0\n",
       "86     1.0\n",
       "87     1.0\n",
       "88     0.0\n",
       "89     1.0\n",
       "90     0.0\n",
       "91     0.0\n",
       "92     0.0\n",
       "93     1.0\n",
       "94     NaN\n",
       "95     0.0\n",
       "96     0.0\n",
       "97     1.0\n",
       "98     0.0\n",
       "99     1.0\n",
       "100    0.0\n",
       "101    0.0\n",
       "102    0.0\n",
       "103    1.0\n",
       "104    0.0\n",
       "105    0.0\n",
       "106    1.0\n",
       "107    0.0\n",
       "108    1.0\n",
       "109    1.0\n",
       "110    0.0\n",
       "111    0.0\n",
       "112    0.0\n",
       "113    1.0\n",
       "114    1.0\n",
       "115    0.0\n",
       "116    0.0\n",
       "117    1.0\n",
       "118    0.0\n",
       "119    0.0\n",
       "120    1.0\n",
       "121    0.0\n",
       "122    1.0\n",
       "123    NaN\n",
       "124    NaN\n",
       "125    0.0\n",
       "126    0.0\n",
       "127    0.0\n",
       "128    0.0\n",
       "129    0.0\n",
       "130    NaN\n",
       "131    0.0\n",
       "132    1.0\n",
       "133    0.0\n",
       "134    1.0\n",
       "135    1.0\n",
       "136    0.0\n",
       "137    1.0\n",
       "138    1.0\n",
       "139    0.0\n",
       "140    0.0\n",
       "141    1.0\n",
       "142    0.0\n",
       "143    0.0\n",
       "144    0.0\n",
       "145    0.0\n",
       "146    0.0\n",
       "147    0.0\n",
       "148    1.0\n",
       "149    1.0\n",
       "150    1.0\n",
       "151    1.0\n",
       "152    0.0\n",
       "153    0.0\n",
       "154    1.0\n",
       "155    0.0\n",
       "156    0.0\n",
       "157    1.0\n",
       "158    0.0\n",
       "159    0.0\n",
       "160    0.0\n",
       "161    0.0\n",
       "162    1.0\n",
       "163    1.0\n",
       "164    0.0\n",
       "165    1.0\n",
       "166    1.0\n",
       "167    0.0\n",
       "168    1.0\n",
       "169    1.0\n",
       "170    0.0\n",
       "171    0.0\n",
       "172    0.0\n",
       "173    1.0\n",
       "174    0.0\n",
       "175    1.0\n",
       "176    1.0\n",
       "177    1.0\n",
       "178    1.0\n",
       "179    0.0\n",
       "180    0.0\n",
       "181    1.0\n",
       "182    1.0\n",
       "183    1.0\n",
       "184    1.0\n",
       "185    0.0\n",
       "186    1.0\n",
       "187    1.0\n",
       "188    0.0\n",
       "189    0.0\n",
       "190    1.0\n",
       "191    1.0\n",
       "192    0.0\n",
       "193    1.0\n",
       "194    0.0\n",
       "195    1.0\n",
       "196    NaN\n",
       "197    1.0\n",
       "198    0.0\n",
       "199    0.0\n",
       "200    0.0\n",
       "201    0.0\n",
       "202    0.0\n",
       "203    0.0\n",
       "204    NaN\n",
       "205    0.0\n",
       "206    0.0\n",
       "207    0.0\n",
       "208    1.0\n",
       "209    1.0\n",
       "210    1.0\n",
       "211    0.0\n",
       "212    0.0\n",
       "213    1.0\n",
       "214    1.0\n",
       "215    0.0\n",
       "216    0.0\n",
       "217    1.0\n",
       "218    0.0\n",
       "219    1.0\n",
       "220    0.0\n",
       "221    1.0\n",
       "222    0.0\n",
       "223    0.0\n",
       "224    0.0\n",
       "225    0.0\n",
       "226    0.0\n",
       "227    0.0\n",
       "228    0.0\n",
       "229    1.0\n",
       "230    NaN\n",
       "231    1.0\n",
       "232    0.0\n",
       "233    0.0\n",
       "234    0.0\n",
       "235    1.0\n",
       "236    1.0\n",
       "237    0.0\n",
       "238    1.0\n",
       "239    0.0\n",
       "240    1.0\n",
       "Name: sex_binary, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_combined['sex_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "train_texts = [\n",
    "    \"nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \",\n",
    "    \"nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef\",\n",
    "    \"nom: Pyrin prénom: Marie date_naissance: 55 relation: d\",\n",
    "    \"nom: Roy prénom: Antoine date_naissance: 51 lieux_naissance: P profession: métro\"\n",
    "]\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {\"Femme\": 0, \"Homme\": 1}\n",
    "train_labels = [label_mapping[label] for label in [\"Femme\", \"Homme\", \"Femme\", \"Homme\"]]\n",
    "df_combined['sex_binary_int'] = df_combined['sex_binary'].astype(int)\n",
    "\n",
    "\n",
    "train_dataset = MyDataset(train_texts, train_labels, tokenizer)\n",
    "val_texts = df_combined['prediction'].tolist()\n",
    "val_labels = df_combined['sex_binary_int'].tolist()\n",
    "\n",
    "val_dataset = MyDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_dataset = MyDataset(train_texts, train_labels, tokenizer)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g3/ll4cqtvn3yx5kfcbb8jfz_p40000gn/T/ipykernel_5652/1096317986.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_combined_no_nan['sex_binary_int'] = df_combined_no_nan['sex_binary'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "train_texts = [\n",
    "    \"nom: Chardon prénom: Marie date_naissance: 30 lieux_naissance: \",\n",
    "    \"nom: Lhopital prénom: Louis Jean date_naissance: 67 lieux_naissance: Sn employeur: ahef\",\n",
    "    \"nom: Pyrin prénom: Marie date_naissance: 55 relation: d\",\n",
    "    \"nom: Roy prénom: Antoine date_naissance: 51 lieux_naissance: P profession: métro\"\n",
    "]\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {\"Femme\": 0, \"Homme\": 1}\n",
    "train_labels = [label_mapping[label] for label in [\"Femme\", \"Homme\", \"Femme\", \"Homme\"]]\n",
    "\n",
    "# Convert labels in df_combined to integers\n",
    "df_combined_no_nan['sex_binary_int'] = df_combined_no_nan['sex_binary'].astype(int)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = MyDataset(train_texts, train_labels, tokenizer)\n",
    "val_texts = df_combined_no_nan['prediction'].tolist()\n",
    "val_labels = df_combined_no_nan['sex_binary_int'].tolist()\n",
    "val_dataset = MyDataset(val_texts, val_labels, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,  # You can adjust this\n",
    "    per_device_train_batch_size=16,  # You can adjust this\n",
    "    per_device_eval_batch_size=64,  # You can adjust this\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=(torch.optim.AdamW(model.parameters(), lr=1e-5), None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 171\n",
      "  Batch size = 64\n",
      "100%|██████████| 3/3 [00:22<00:00,  7.65s/it]\n"
     ]
    }
   ],
   "source": [
    "result = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 171\n",
      "  Batch size = 64\n",
      "100%|██████████| 3/3 [00:23<00:00,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4853801169590643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "result = trainer.evaluate()\n",
    "\n",
    "print(result['eval_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'accuracy'"
     ]
    }
   ],
   "source": [
    "print(result['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bert + Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file tokenizer.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/anthonyivanier/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "/Users/anthonyivanier/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Encode sentences to get embeddings\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embeddings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     kmeans \u001b[38;5;241m=\u001b[39m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: Input embeddings are None or empty.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:1513\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1512\u001b[0m     kmeans_single \u001b[38;5;241m=\u001b[39m _kmeans_single_lloyd\n\u001b[0;32m-> 1513\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_mkl_vcomp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1515\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:927\u001b[0m, in \u001b[0;36m_BaseKMeans._check_mkl_vcomp\u001b[0;34m(self, X, n_samples)\u001b[0m\n\u001b[1;32m    925\u001b[0m n_active_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(n_samples \u001b[38;5;241m/\u001b[39m CHUNK_SIZE))\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_active_threads \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_threads:\n\u001b[0;32m--> 927\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[43mthreadpool_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m     has_vcomp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvcomp\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [module[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprefix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules]\n\u001b[1;32m    929\u001b[0m     has_mkl \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintel\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    930\u001b[0m         (module[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal_api\u001b[39m\u001b[38;5;124m\"\u001b[39m], module\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreading_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m modules\n\u001b[1;32m    932\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/fixes.py:85\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m controller\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mthreadpoolctl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreadpool_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:124\u001b[0m, in \u001b[0;36mthreadpool_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;129m@_format_docstring\u001b[39m(USER_APIS\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlist\u001b[39m(_ALL_USER_APIS),\n\u001b[1;32m    108\u001b[0m                    INTERNAL_APIS\u001b[38;5;241m=\u001b[39m_ALL_INTERNAL_APIS)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mthreadpool_info\u001b[39m():\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the maximal number of threads for each detected library.\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    Return a list with all the supported modules that have been found. Each\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    In addition, each module may contain internal_api specific entries.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ThreadpoolInfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_api\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_ALL_USER_APIS\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtodicts()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:340\u001b[0m, in \u001b[0;36m_ThreadpoolInfo.__init__\u001b[0;34m(self, user_api, prefixes, modules)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;28;01mif\u001b[39;00m user_api \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m user_api\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_modules\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_if_incompatible_openmp()\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:371\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._load_modules\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;124;03m\"\"\"Loop through loaded libraries and store supported ones\"\"\"\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdarwin\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 371\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_modules_with_dyld\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mplatform \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwin32\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_find_modules_with_enum_process_module_ex()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:428\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._find_modules_with_dyld\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m filepath \u001b[38;5;241m=\u001b[39m filepath\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# Store the module if it is supported and selected\u001b[39;00m\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_module_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:515\u001b[0m, in \u001b[0;36m_ThreadpoolInfo._make_module_from_path\u001b[0;34m(self, filepath)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprefixes \u001b[38;5;129;01mor\u001b[39;00m user_api \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_api:\n\u001b[1;32m    514\u001b[0m     module_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mglobals\u001b[39m()[module_class]\n\u001b[0;32m--> 515\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mmodule_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_api\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_api\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mappend(module)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:606\u001b[0m, in \u001b[0;36m_Module.__init__\u001b[0;34m(self, filepath, prefix, user_api, internal_api)\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minternal_api \u001b[38;5;241m=\u001b[39m internal_api\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mCDLL(filepath, mode\u001b[38;5;241m=\u001b[39m_RTLD_NOLOAD)\n\u001b[0;32m--> 606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_version\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_threads()\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_extra_info()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/threadpoolctl.py:646\u001b[0m, in \u001b[0;36m_OpenBLASModule.get_version\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    643\u001b[0m get_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dynlib, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenblas_get_config\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    644\u001b[0m                      \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    645\u001b[0m get_config\u001b[38;5;241m.\u001b[39mrestype \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p\n\u001b[0;32m--> 646\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m()\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenBLAS\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Encode sentences to get embeddings\n",
    "if embeddings is not None:\n",
    "    kmeans = KMeans(n_clusters=2, random_state=0).fit(embeddings)\n",
    "else:\n",
    "    print(\"Error: Input embeddings are None or empty.\")\n",
    "for i in range(2):\n",
    "    mask = (kmeans.labels_ == i)\n",
    "    labels[mask] = mode(df_combined['sex_binary'][mask])[0]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_combined['sex_binary'], labels)\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
